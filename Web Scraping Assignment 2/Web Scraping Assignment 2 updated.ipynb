{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5307bf",
   "metadata": {},
   "source": [
    "#### Web Scarping Assignment 2 (Selenium) - Vinayak Ratan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869bcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries required to Scrape data using Selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3154b6",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "### have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "### jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1c1d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e9fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.naukri.com/ to scrape data \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe15831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Analyst” in “Skill, Designations, Companies” field\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f639c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Bangalore” in “enter the location” field.\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce7fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click the search button\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f58a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "job_title =[]\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_reqd = []\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping Job Location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)   \n",
    "\n",
    "    \n",
    "# Scraping Company Name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_reqd.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8ae44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of each data scarped before creating the dataframe\n",
    "print(len(job_title), len(job_location), len(company_name), len(experience_reqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462d4933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- First 10 jobs in “Data Analyst” Job position in “Bangalore” location ---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-reqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intern Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>FullStackTechies</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Python/Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>iMindYourBusiness</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Leap COE Intern(Data Analyst)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Info Origin Inc.</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job-title  \\\n",
       "0                              Senior Data Analyst   \n",
       "1                                 Sr. Data Analyst   \n",
       "2          Master Data Management Business Analyst   \n",
       "3                              Senior Data Analyst   \n",
       "4                              Intern Data Analyst   \n",
       "5    Data Analyst - Python/Artificial Intelligence   \n",
       "6                                Lead Data Analyst   \n",
       "7                                     Data Analyst   \n",
       "8                    Leap COE Intern(Data Analyst)   \n",
       "9  Forecasting Analyst/ Data Scientist (US Client)   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0               Bangalore/Bengaluru(Old Madras Road)   \n",
       "1                          Bangalore/Bengaluru, Pune   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Gurgaon/Gurugram\\n(WFH du...   \n",
       "\n",
       "                              Company-name Experience-reqd  \n",
       "0                                 KrazyBee         3-6 Yrs  \n",
       "1  Global Indian School Education Services        6-11 Yrs  \n",
       "2                                Accenture         6-8 Yrs  \n",
       "3                                    Optum         5-7 Yrs  \n",
       "4                         FullStackTechies         0-1 Yrs  \n",
       "5                        iMindYourBusiness         0-2 Yrs  \n",
       "6                                   McAfee         5-9 Yrs  \n",
       "7                                    Bayer         2-5 Yrs  \n",
       "8                         Info Origin Inc.         0-1 Yrs  \n",
       "9                               Concentrix         3-8 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame for the first 10 jobs for Data Analyst in Bangalore\n",
    "data_analyst = pd.DataFrame({'Job-title':job_title, 'Job-location':job_location,\"Company-name\": company_name, \"Experience-reqd\": experience_reqd})\n",
    "print('-'*15,\"First 10 jobs in “Data Analyst” Job position in “Bangalore” location\",'-'*15)\n",
    "data_analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafd618",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "### have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f0d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534596c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.naukri.com/ to scrape data \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec82d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill, Designations, Companies” field\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c184597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Bangalore” in “enter the location” field.\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320e8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click the search button\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3e581ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "job_title_ds =[]\n",
    "job_location_ds = []\n",
    "company_name_ds = []\n",
    "experience_reqd_ds = []\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title_ds.append(title)\n",
    "\n",
    "# Scraping Job Location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location_ds.append(location)   \n",
    "\n",
    "    \n",
    "# Scraping Company Name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name_ds.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_reqd_ds.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3ad6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of each data scarped before creating the dataframe\n",
    "print(len(job_title_ds), len(job_location_ds), len(company_name_ds), len(experience_reqd_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ede90a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- First 10 jobs in “Data Scientist” Job position in “Bangalore” location ---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-reqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>11-20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Python</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Conduent</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0                      Tcs Hiring For Data Scientist   \n",
       "1   Senior Manager - EmTech - Machine Learning - P&T   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "4  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "5  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "6  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "7                              Data Scientist Python   \n",
       "8                   Assistant Manager - Data Science   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "4  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "5  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "6  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "7        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "8                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                  Company-name Experience-reqd  \n",
       "0              TATA CONSULTANCY SERVICES (TCS)         3-8 Yrs  \n",
       "1                                          PwC        5-12 Yrs  \n",
       "2                                    Accenture         6-8 Yrs  \n",
       "3              TATA CONSULTANCY SERVICES (TCS)        9-14 Yrs  \n",
       "4                                        Wipro        5-10 Yrs  \n",
       "5  NTT DATA Business Solutions Private Limited         4-9 Yrs  \n",
       "6                                        Wipro       11-20 Yrs  \n",
       "7                                     Conduent         3-7 Yrs  \n",
       "8                                   CitiusTech         5-9 Yrs  \n",
       "9                                   Concentrix        7-12 Yrs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame for the first 10 jobs for Data Scientist in Bangalore\n",
    "data_scientist = pd.DataFrame({'Job-title':job_title_ds, 'Job-location':job_location_ds,\"Company-name\": company_name_ds, \"Experience-reqd\": experience_reqd_ds})\n",
    "print('-'*15,\"First 10 jobs in “Data Scientist” Job position in “Bangalore” location\",'-'*15)\n",
    "data_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0bcdb",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:       \n",
    "### You have to use the location and salary filter.\n",
    "### You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "### You have to scrape the job-title, job-location, company name, experience required.\n",
    "### The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45939460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56f7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.naukri.com/ to scrape data \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0448b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill, Designations, Companies” field\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab31ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Delhi/NCR” in “enter the location” field.\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91aa5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click the search button to go to the respective page\n",
    "search = driver.find_element(By.CLASS_NAME, \"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cb4f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data based on Salary from “3-6” lakhs\n",
    "filter_sal = driver.find_element(By.XPATH, '//span[@title=\"3-6 Lakhs\"]')\n",
    "filter_sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94725384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "job_title_ds_delhi =[]\n",
    "job_location_ds_delhi = []\n",
    "company_name_ds_delhi = []\n",
    "experience_reqd_ds_delhi = []\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title_ds_delhi.append(title)\n",
    "\n",
    "# Scraping Job Location from the given page\n",
    "location_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location_ds_delhi.append(location)   \n",
    "\n",
    "    \n",
    "# Scraping Company Name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name_ds_delhi.append(company)\n",
    "    \n",
    "\n",
    "\n",
    "# Scraping Job title from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH, '//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_reqd_ds_delhi.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e976dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n",
      "--------------- First 10 jobs in “Data Scientist” Job position in “Delhi/NCR” location ---------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-reqd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Risk / Fraud L1</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Risk Platform</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "1                   Data Scientist - Risk / Fraud L1   \n",
       "2                   Data Scientist - Noida/Bangalore   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                     Data Scientist - Risk Platform   \n",
       "8                                 Decision Scientist   \n",
       "9                    DigitalBCG GAMMA Data Scientist   \n",
       "\n",
       "                                        Job-location             Company-name  \\\n",
       "0  New Delhi, Hyderabad/Secunderabad, Pune, Chenn...                    Wipro   \n",
       "1                                Bangalore/Bengaluru                    Gojek   \n",
       "2                         Noida, Bangalore/Bengaluru                      EXL   \n",
       "3                                Bangalore/Bengaluru                  Infosys   \n",
       "4                                Bangalore/Bengaluru        Applied Materials   \n",
       "5                                Bangalore/Bengaluru        Applied Materials   \n",
       "6                                Bangalore/Bengaluru        Applied Materials   \n",
       "7                                Bangalore/Bengaluru                    Gojek   \n",
       "8                                Bangalore/Bengaluru                    Gojek   \n",
       "9                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "\n",
       "  Experience-reqd  \n",
       "0        5-10 Yrs  \n",
       "1         1-2 Yrs  \n",
       "2        5-10 Yrs  \n",
       "3         2-7 Yrs  \n",
       "4         2-4 Yrs  \n",
       "5         4-7 Yrs  \n",
       "6         2-4 Yrs  \n",
       "7        5-11 Yrs  \n",
       "8         4-9 Yrs  \n",
       "9         2-5 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of each data scarped before creating the dataframe\n",
    "print(len(job_title_ds_delhi), len(job_location_ds_delhi), len(company_name_ds_delhi), len(experience_reqd_ds_delhi))\n",
    "\n",
    "# Creating the DataFrame for the first 10 jobs for 'Data Scientist' in 'Delhi/NCR'\n",
    "data_scientist_delhi = pd.DataFrame({'Job-title':job_title_ds_delhi, 'Job-location':job_location_ds_delhi,\"Company-name\": company_name_ds_delhi, \"Experience-reqd\": experience_reqd_ds_delhi})\n",
    "print('-'*15,\"First 10 jobs in “Data Scientist” Job position in “Delhi/NCR” location\",'-'*15)\n",
    "data_scientist_delhi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108e1b5",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "### 1. Brand\n",
    "### 2. Product Description\n",
    "### 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a57ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fd187b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.flipkart.com/ to scrape data \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11a2e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login pop-up\n",
    "close_login = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b8c5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “sunglasses” in the search field where “search for products, brands and more” is written\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ac32596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "360de1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 119 120 120\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_sg =[]\n",
    "product_description_sg = []\n",
    "price_sg = []\n",
    "discount_sg = []\n",
    "\n",
    "\n",
    "# Scarping 100 sunglasses\n",
    "for page in range(0,3):\n",
    "    # Scraping the brand names of the sunglasses\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in brand_tags:\n",
    "        brand_sg.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of sunglasses\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for pr_des in product_description_tags:\n",
    "        product_description_sg.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the sunglasses\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for price in price_tags:\n",
    "        price_sg.append(price.text)\n",
    "        \n",
    "    # Scraping the \"Discount\" given for the sunglasses\n",
    "    discount_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for discount in discount_tags:\n",
    "        discount_sg.append(discount.text)\n",
    "        \n",
    "    # Moving the next page of sunglasses\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "print(len(brand_sg),len(product_description_sg),len(price_sg),len(discount_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b9da107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 sunglasses -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹204</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fair-x</td>\n",
       "      <td>Mirrored, Riding Glasses, UV Protection Sports...</td>\n",
       "      <td>₹360</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹195</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Polarized, UV Protection, Gradient, Riding Gla...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0      ROZZETTA CRAFT   Polarized, UV Protection Aviator Sunglasses (55)   \n",
       "1      ROZZETTA CRAFT   Polarized, UV Protection Aviator Sunglasses (55)   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3            DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...   \n",
       "4                SRPM             UV Protection Wayfarer Sunglasses (50)   \n",
       "..                ...                                                ...   \n",
       "95             Fair-x  Mirrored, Riding Glasses, UV Protection Sports...   \n",
       "96     ROZZETTA CRAFT  Polarized, Riding Glasses Sports, Wrap-around ...   \n",
       "97           Fastrack        UV Protection Shield Sunglasses (Free Size)   \n",
       "98  SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "99       CRYSTAL CART  Polarized, UV Protection, Gradient, Riding Gla...   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹499  75% off  \n",
       "1   ₹499  75% off  \n",
       "2   ₹799  20% off  \n",
       "3   ₹204  79% off  \n",
       "4   ₹189  85% off  \n",
       "..   ...      ...  \n",
       "95  ₹360  75% off  \n",
       "96  ₹499  75% off  \n",
       "97  ₹719  20% off  \n",
       "98  ₹195  88% off  \n",
       "99  ₹349  76% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 sunglasses\n",
    "sunglasses_df = pd.DataFrame({'Brand':brand_sg[0:100], 'Product Description':product_description_sg[0:100],\"Price\":price_sg[0:100], \"Discount\":discount_sg[0:100]})\n",
    "print('-'*25,\"First 100 sunglasses\",'-'*25)\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa042b",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "### As given in the page you have to scrape the tick marked attributes.These are:\n",
    "### 1. Rating\n",
    "### 2. Review summary\n",
    "### 3. Full review\n",
    "### 4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4890252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77f3a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.flipkart.com/ to scrape data \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f075051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login pop-up\n",
    "close_login = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25fcfd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “iphone 11” in the search field\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c762aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3aa6b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the first iphone, then later scraping ratings, review summary and full review\n",
    "iphone11 = driver.find_element(By.CLASS_NAME,\"_4rR01T\")\n",
    "iphone11.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c38a4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the all 6810 reviews\n",
    "# all_reviews = driver.find_element(By.XPATH, '')\n",
    "# all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26449f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 120 120\n"
     ]
    }
   ],
   "source": [
    "# Creating empty list to scrape required data\n",
    "rating_ip11 =[]\n",
    "review_summary_ip11 =[]\n",
    "full_review_ip11 =[]\n",
    "\n",
    "\n",
    "# Using nested for loop to scrape 100 review details for \"iphone 11\"\n",
    "# Since on the page only 10 reviews are available after inspecting, we need to click on '+' to get more reviews\n",
    "for ip_11 in range(0,20):\n",
    "    # Scraping the rating of \"iphone 11\"\n",
    "    rating = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for rt in rating:\n",
    "        rating_ip11.append(rt.text)\n",
    "        \n",
    "    # Scraping the review summary for \"iphone 11\"\n",
    "    review_summary = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "    for rs in review_summary:\n",
    "        review_summary_ip11.append(rs.text)\n",
    "        \n",
    "    # Scraping the full review for \"iphone 11\"\n",
    "    full_review = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]//div//div')\n",
    "    for fr in full_review:\n",
    "        full_review_ip11.append(fr.text)\n",
    "        \n",
    "    # clicking on the '+' button to get other reviews\n",
    "#     all_reviews.click()\n",
    "#     time.sleep(2)\n",
    "\n",
    "\n",
    "print(len(rating_ip11),len(review_summary_ip11), len(full_review_ip11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d288aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 reviews of iphone 11 -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Nice product thank you Flipkart ❤️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Best phone still @25-27K</td>\n",
       "      <td>Purchased at BBD @2016 Oct. After 5months of u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Nice product thank you Flipkart ❤️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating            Review Summary  \\\n",
       "0       4      Good quality product   \n",
       "1       5          Perfect product!   \n",
       "2       5            Simply awesome   \n",
       "3       5            Simply awesome   \n",
       "4       5  Best phone still @25-27K   \n",
       "..    ...                       ...   \n",
       "95      4                  Terrific   \n",
       "96      5      Good quality product   \n",
       "97      5          Perfect product!   \n",
       "98      5            Simply awesome   \n",
       "99      5            Simply awesome   \n",
       "\n",
       "                                          Full review  \n",
       "0   impressively Nice......\\nOne of the greatest i...  \n",
       "1                          Nice products thanks flkat  \n",
       "2   Really satisfied with the Product I received.....  \n",
       "3                  Nice product thank you Flipkart ❤️  \n",
       "4   Purchased at BBD @2016 Oct. After 5months of u...  \n",
       "..                                                ...  \n",
       "95  I am using the phone for last 5 years and foun...  \n",
       "96  impressively Nice......\\nOne of the greatest i...  \n",
       "97                         Nice products thanks flkat  \n",
       "98  Really satisfied with the Product I received.....  \n",
       "99                 Nice product thank you Flipkart ❤️  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'iphone 11' reviews\n",
    "ip11_df = pd.DataFrame({'Rating':rating_ip11,'Review Summary':review_summary_ip11[0:100], 'Full review': full_review_ip11[0:100]})\n",
    "print('-'*25,\"First 100 reviews of iphone 11\",'-'*25)\n",
    "ip11_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8adce4",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "### search field.\n",
    "### You have to scrape 4 attributes of each sneaker:\n",
    "### 1. Brand\n",
    "### 2. Product Description\n",
    "### 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1698c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16dd6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.flipkart.com/ to scrape data \n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12d48269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login pop-up\n",
    "close_login = driver.find_element(By.XPATH, '//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f03e58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Sneakers” in the search field\n",
    "product = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ed67920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.CLASS_NAME, \"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e8cbfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 109 120 120\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "brand_sks =[]\n",
    "product_description_sks = []\n",
    "price_sks = []\n",
    "discount_sks = []\n",
    "\n",
    "\n",
    "# Scarping 100 'Sneakers'\n",
    "for page in range(0,3):\n",
    "    # Scraping the brand names of the 'Sneakers'\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for brand in brand_tags[0:100]:\n",
    "        brand_sks.append(brand.text)\n",
    "        \n",
    "    # Scraping the product description of 'Sneakers'\n",
    "    product_description_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "    for pr_des in product_description_tags[0:100]:\n",
    "        product_description_sks.append(pr_des.text)\n",
    "    \n",
    "    # Scraping the 'Price' of the 'Sneakers'\n",
    "    price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "    for price in price_tags[0:100]:\n",
    "        price_sks.append(price.text)\n",
    "        \n",
    "    # Scraping the \"Discount\" given for the 'Sneakers'\n",
    "    discount_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for discount in discount_tags[0:100]:\n",
    "        discount_sks.append(discount.text)\n",
    "        \n",
    "    # Moving the next page of 'Sneakers'\n",
    "    next_page = driver.find_element(By.XPATH, '//a[@class=\"_1LKTO3\"]//span')\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "print(len(brand_sks),len(product_description_sks),len(price_sks),len(discount_sks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "247a2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 100 Sneakers -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹204</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fair-x</td>\n",
       "      <td>Mirrored, Riding Glasses, UV Protection Sports...</td>\n",
       "      <td>₹360</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, Riding Glasses Sports, Wrap-around ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹195</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Polarized, UV Protection, Gradient, Riding Gla...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0      ROZZETTA CRAFT   Polarized, UV Protection Aviator Sunglasses (55)   \n",
       "1      ROZZETTA CRAFT   Polarized, UV Protection Aviator Sunglasses (55)   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3            DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...   \n",
       "4                SRPM             UV Protection Wayfarer Sunglasses (50)   \n",
       "..                ...                                                ...   \n",
       "95             Fair-x  Mirrored, Riding Glasses, UV Protection Sports...   \n",
       "96     ROZZETTA CRAFT  Polarized, Riding Glasses Sports, Wrap-around ...   \n",
       "97           Fastrack        UV Protection Shield Sunglasses (Free Size)   \n",
       "98  SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "99       CRYSTAL CART  Polarized, UV Protection, Gradient, Riding Gla...   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹499  75% off  \n",
       "1   ₹499  75% off  \n",
       "2   ₹799  20% off  \n",
       "3   ₹204  79% off  \n",
       "4   ₹189  85% off  \n",
       "..   ...      ...  \n",
       "95  ₹360  75% off  \n",
       "96  ₹499  75% off  \n",
       "97  ₹719  20% off  \n",
       "98  ₹195  88% off  \n",
       "99  ₹349  76% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 100 'Sneakers'\n",
    "sneakers_df = pd.DataFrame({'Brand':brand_sg[0:100], 'Product Description':product_description_sg[0:100],\"Price\":price_sg[0:100], \"Discount\":discount_sg[0:100]})\n",
    "print('-'*25,\"First 100 Sneakers\",'-'*25)\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eaf487",
   "metadata": {},
   "source": [
    "### Q7: Go to the link - https://www.myntra.com/shoes\n",
    "### Set second Price filter and Color filter to “Black”,\n",
    "### And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "### description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e56e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28afaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.myntra.com/shoes to scrape data \n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00104c19",
   "metadata": {},
   "source": [
    "- Unable to right click and inspect. Due to this reason the required data cannot be scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02d8e7",
   "metadata": {},
   "source": [
    "### Q8: Go to webpage https://www.amazon.in/\n",
    "### Enter “Laptop” in the search field and then click the search icon.\n",
    "### Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "### After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "### 1. Title\n",
    "### 2. Ratings\n",
    "### 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42cd9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "driver = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60dc00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.amazon.in/ to scrape data \n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e863c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Laptop” in the search field \n",
    "product = driver.find_element(By.XPATH,'//input[@type=\"text\"]')\n",
    "product.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "356801fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search icon after entering the product name\n",
    "search = driver.find_element(By.XPATH, '//input[@id=\"nav-search-submit-button\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "706e47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the laptops based on “Intel Core i7”\n",
    "filter_laptop = driver.find_element(By.XPATH,'//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\" and @aria-label=\"Intel Core i7\" ]//span')\n",
    "filter_laptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "430c07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data to be scraped \n",
    "title_laptop = []\n",
    "ratings_laptop = []\n",
    "price_laptop = []\n",
    "\n",
    "\n",
    "# Scraping the title of laptops\n",
    "title = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for t in title[0:10]:\n",
    "    title_laptop.append(t.text)\n",
    "\n",
    "    \n",
    "# Scraping the ratings of laptop\n",
    "ratings = driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for r in ratings[0:10]:\n",
    "    ratings_laptop.append(r.get_attribute('text'))\n",
    "    \n",
    "\n",
    "# Scraping the price of laptop\n",
    "price = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]')\n",
    "for p in price[0:10]:\n",
    "    price_laptop.append(p.text)\n",
    "    \n",
    "print(len(title_laptop),len(ratings_laptop),len(price_laptop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6bef107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2 out of 5 stars',\n",
       " '3.9 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '3.6 out of 5 stars',\n",
       " '4.0 out of 5 stars',\n",
       " '3.6 out of 5 stars',\n",
       " '4.7 out of 5 stars',\n",
       " '4.5 out of 5 stars',\n",
       " '4.2 out of 5 stars',\n",
       " '4.4 out of 5 stars']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers_df['Ratings'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ea3e4",
   "metadata": {},
   "source": [
    "obtained the text for ratings using 'get_attribute', r.text was giving empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "88638735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 10 Laptops -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>82,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>56,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17\"(43cm)Ul...</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>92,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "1  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...  3.9 out of 5 stars   \n",
       "2  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  4.1 out of 5 stars   \n",
       "3  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.6 out of 5 stars   \n",
       "4  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  4.0 out of 5 stars   \n",
       "5  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "6  LG Gram Intel Evo 11th Gen Core i7 17\"(43cm)Ul...  4.7 out of 5 stars   \n",
       "7  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...  4.5 out of 5 stars   \n",
       "8  ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...  4.2 out of 5 stars   \n",
       "9  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...  4.4 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    89,990  \n",
       "1    62,990  \n",
       "2    82,400  \n",
       "3    56,590  \n",
       "4    87,990  \n",
       "5    79,490  \n",
       "6    92,999  \n",
       "7  1,09,990  \n",
       "8    82,990  \n",
       "9    94,990  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for 10 'Laptops'\n",
    "sneakers_df = pd.DataFrame({'Title':title_laptop[0:10], 'Ratings':ratings_laptop[0:10],\"Price\":price_laptop[0:10]})\n",
    "print('-'*25,\"First 10 Laptops\",'-'*25)\n",
    "sneakers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a24b",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "### location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "### This task will be done in following steps:\n",
    "### 1. First get the webpage https://www.ambitionbox.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9c39875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "ab = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d030d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.ambitionbox.com/ to scrape data \n",
    "ab.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d1a74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Job option\n",
    "job_op = ab.find_element(By.CLASS_NAME, 'navItemLink')\n",
    "job_op.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c37ecf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search by Designations, Companies, Skills” enter “Data Scientist”\n",
    "post = ab.find_element(By.XPATH, '//input[@title=\"Enter Designation, Company or a Skill\"]')\n",
    "post.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1f495dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button.\n",
    "search = ab.find_element(By.XPATH, '//button[@class=\"ab_btn search-btn round\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fed3aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on location\n",
    "location = ab.find_element(By.XPATH, '//div[@title=\"Location\"]')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2bd71f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering the location 'Noida'\n",
    "noida = ab.find_element(By.XPATH, '//input[@placeholder=\"Search locations\"]')\n",
    "noida.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64290809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Noida\n",
    "search1 = ab.find_element(By.XPATH, '//label[@for=\"location_Noida\"]')\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "49033b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty list for the data\n",
    "name_company = []\n",
    "job_post_days =[]\n",
    "rating_company =[]\n",
    "\n",
    "\n",
    "# Scraping the name of the company\n",
    "company = ab.find_elements(By.XPATH, '//p[@class=\"company body-medium\"]')\n",
    "for c in company:\n",
    "    name_company.append(c.text)\n",
    "    \n",
    "# Scraping the Number of days ago when job was posted \n",
    "days = ab.find_elements(By.XPATH, '//span[@class=\"body-small-l\"]')\n",
    "for d in days:\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in range(len(days)):\n",
    "        if i % 2 == 0:\n",
    "            a.append(days[i].text)\n",
    "        elif i % 2 == 1:\n",
    "            b.append(days[i].text)\n",
    "job_post_days = a\n",
    "    \n",
    "# Scraping the Rating of the Company\n",
    "rtg = ab.find_elements(By.XPATH, '//span[@class=\"body-small\"]')\n",
    "for r in rtg:\n",
    "    rating_company.append(r.text)\n",
    "    \n",
    "print(len(name_company),len(job_post_days),len(rating_company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c032eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- First 10 job results -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job posted days</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>18hr ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>13d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>26d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SOPRA STERIA INDIA LIMITED</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EY</td>\n",
       "      <td>25d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company Job posted days Rating\n",
       "0                         CBRE South Asia Pvt Ltd          6d ago    4.3\n",
       "1                                         Genpact        18hr ago    4.0\n",
       "2        Ericsson India Global Services Pvt. Ltd.         16d ago    4.3\n",
       "3                   GENPACT India Private Limited          9d ago    4.0\n",
       "4  Optum Global Solutions (India) Private Limited         13d ago    4.1\n",
       "5  Optum Global Solutions (India) Private Limited         14d ago    4.1\n",
       "6        Ericsson India Global Services Pvt. Ltd.         26d ago    4.3\n",
       "7                      SOPRA STERIA INDIA LIMITED         15d ago    4.2\n",
       "8                EXL Services.com ( I ) Pvt. Ltd.         15d ago    3.9\n",
       "9                                              EY         25d ago    3.8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for first 10 job results \n",
    "jobs_df = pd.DataFrame({'Company':name_company, 'Job posted days':job_post_days,\"Rating\":rating_company})\n",
    "print('-'*25,\"First 10 job results\",'-'*25)\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbad486",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "### You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "### webpage https://www.ambitionbox.com/\n",
    "#### Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "#### salary, minimum salary, maximum salary, experience required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "defc26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the driver, using chromedriver\n",
    "ab1 = webdriver.Chrome(r'G:\\AI Professional\\Data Trained\\Internship Fliprobo Technologies\\Webscraping (Selenium)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "944cab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the webpage https://www.ambitionbox.com/ to scrape data \n",
    "ab1.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "19252b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Salaries option\n",
    "salary_op = ab1.find_element(By.XPATH, '/html/body/div[1]/nav[2]/div/ul/li[3]/a')\n",
    "action = webdriver.ActionChains(ab1)\n",
    "action.move_to_element(salary_op)\n",
    "action.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "efd50f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuation on the Salaries option\n",
    "salary_browse = ab1.find_element(By.XPATH, '//a[@title=\"Browse salaries\"]')\n",
    "salary_browse.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c9c1df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search Job Profile” enters “Data Scientist”\n",
    "data_sc = ab1.find_element(By.XPATH, '//input[@type=\"searchbox\"]')\n",
    "data_sc.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e447354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then click on “Data Scientist”\n",
    "ds = ab1.find_element(By.XPATH, '/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "ds.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2463635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# Creating the empty list for the required data to be scraped\n",
    "company_n = []\n",
    "total_salary_record=[]\n",
    "avg_salary = []\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "exp_reqd =[]\n",
    "\n",
    "# Getting the names of the company\n",
    "cn = ab1.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for n in cn[0:10]:\n",
    "    cd = n.text.split()[:-10]\n",
    "    name = ''\n",
    "    company_n.append(name.join(cd))\n",
    "\n",
    "# Getting the total salary record of the company\n",
    "cn = ab1.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for n in cn[0:10]:\n",
    "    s = n.text.split()[-2:]\n",
    "    total_salary_record.append(s[0])\n",
    "\n",
    "# Getting the average salary of the company\n",
    "avg_s = ab1.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for av in avg_s:\n",
    "    avg_salary.append(av.text)\n",
    "\n",
    "# Getting the Maximum and Minimum salary of the company\n",
    "max_min_s = ab1.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for mm in range(len(max_min_s)):\n",
    "    if mm % 2 == 0:\n",
    "        min_salary.append(max_min_s[mm].text)\n",
    "    elif mm % 2 == 1:\n",
    "        max_salary.append(max_min_s[mm].text)\n",
    "        \n",
    "# Getting the experience required\n",
    "exp = ab1.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for er in exp[0:10]:\n",
    "    ex = er.text.split()[:-4]\n",
    "    exp_reqd.append(ex[0]+' '+ex[1])\n",
    "\n",
    "print(len(company_n),len(total_salary_record),len(avg_salary),len(max_salary),len(min_salary),len(exp_reqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "91fd355f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- First 10 the salary data for Data Scientist designation  ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total salary record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Experince Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>22</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbInbev</td>\n",
       "      <td>53</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>48</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>33</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>1-2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FractalAnalytics</td>\n",
       "      <td>109</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TigerAnalytics</td>\n",
       "      <td>65</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LegatoHealthTechnologies</td>\n",
       "      <td>11</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>12</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>91</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FordMotor</td>\n",
       "      <td>21</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>3-4 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Total salary record Average Salary Maximum Salary  \\\n",
       "0                   Walmart                  22        ₹ 31.7L        ₹ 45.0L   \n",
       "1                   AbInbev                  53        ₹ 19.7L        ₹ 25.5L   \n",
       "2                     Optum                  48        ₹ 16.5L        ₹ 22.6L   \n",
       "3                        ZS                  33        ₹ 15.7L        ₹ 22.0L   \n",
       "4          FractalAnalytics                 109        ₹ 15.2L        ₹ 23.0L   \n",
       "5            TigerAnalytics                  65        ₹ 14.7L        ₹ 20.0L   \n",
       "6  LegatoHealthTechnologies                  11        ₹ 14.5L        ₹ 20.0L   \n",
       "7                  Tredence                  12        ₹ 14.1L        ₹ 17.5L   \n",
       "8              UnitedHealth                  91        ₹ 13.6L        ₹ 20.5L   \n",
       "9                 FordMotor                  21        ₹ 13.5L        ₹ 18.0L   \n",
       "\n",
       "  Minimum Salary Experince Required  \n",
       "0        ₹ 25.0L            3-4 yrs  \n",
       "1        ₹ 15.0L            2-4 yrs  \n",
       "2        ₹ 11.0L            2-4 yrs  \n",
       "3        ₹ 11.0L            1-2 yrs  \n",
       "4         ₹ 9.0L            2-4 yrs  \n",
       "5         ₹ 9.0L            2-4 yrs  \n",
       "6        ₹ 11.0L              4 yrs  \n",
       "7         ₹ 8.8L              3 yrs  \n",
       "8         ₹ 8.0L            2-4 yrs  \n",
       "9        ₹ 10.0L            3-4 yrs  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame for first 10 the salary data for Data Scientist designation \n",
    "salary_df = pd.DataFrame({'Company Name':company_n, 'Total salary record':total_salary_record,'Average Salary':avg_salary,\n",
    "                         'Maximum Salary':max_salary,'Minimum Salary':min_salary,'Experince Required':exp_reqd})\n",
    "print('-'*10,\"First 10 the salary data for Data Scientist designation \",'-'*10)\n",
    "salary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d54a51",
   "metadata": {},
   "source": [
    "- Note: In some cases the length of the scraped data was not the same but the scraped data was sufficient to create a DataFrame as asked in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9d828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
